{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7ED8jpSDZeb",
    "outputId": "5d020244-05ff-4e23-b470-d3dd89318ea2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/talha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from singularizer_french import singularize\n",
    "from re import compile as recompile\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_units():\n",
    "    ml = []\n",
    "    with open(\"units_data/ml.txt\") as f:\n",
    "        ml =[singularize(re.sub(\"\\n\",\"\",a).strip().lower()) for a in f.readlines() if len(a)>0]\n",
    "    \n",
    "    gram = []\n",
    "    with open(\"units_data/gram.txt\") as f:\n",
    "        gram = [singularize(re.sub(\"\\n\",\"\",a).strip().lower()) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "    return ml,gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divider(number):\n",
    "    a_q = number.split(\"/\")\n",
    "    a1 = int(a_q[0])\n",
    "    a2 = int(a_q[1])\n",
    "    return a1/a2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unit(substring4,unit,quantity_product,ml,gram,m):\n",
    "    for m in ml:\n",
    "        if m in substring4 and len(m)>0 and unit !=\"l\":\n",
    "            try:\n",
    "                if unit == \"kg\":\n",
    "                    return quantity_product,\"l\"\n",
    "                else:\n",
    "                    return quantity_product/1000,\"l\"\n",
    "            except:\n",
    "                return divider(quantity_product)/1000,\"l\"\n",
    "    for g in gram:\n",
    "        if g in substring4 and len(g)>0 and unit !=\"kg\":\n",
    "            try:\n",
    "                if unit == \"l\":\n",
    "                    return quantity_product,\"kg\"\n",
    "                else:\n",
    "                    return quantity_product/1000,\"kg\"\n",
    "            except:\n",
    "                return divider(quantity_product)/1000,\"kg\"\n",
    "            \n",
    "    return quantity_product,unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9xMMGNO7m0E",
    "outputId": "e61da46f-1cd1-487a-b325-c5d3fd647fd2"
   },
   "outputs": [],
   "source": [
    "def process(input_json_data,ml,gram):\n",
    "\n",
    "    data = input_json_data\n",
    "    df = None\n",
    "    des,quantity,unit = [],[],[]\n",
    "    \n",
    "    unknow_words = [\"nature\",\"jeune\",\"cuillères\",\"cuillère\",\"à\",\"thé\",\"cuillère à thé\",\"en\",\"dés\",\"hachée\",\"hachées\",\"grossièrement\",\"divisées\",\"finement\",\"facultatif\",\"haché\",\"tassées\",\"boîte\",\"de\",\"soupe\",\"conserve\",\"bouillon\",\"gousses\",\"gousse\",\"grosse\",\"gross\",\"gros\",\"lanières\",\"livre\",\"onces\",\"paquet\",\"petit\",\"petite\",\"récipients\",\"sachet\",\"tasse\",\"tasses\",\"râpé\",\"non cuit\",\"cuit\",\"cuits\",\"tranche\",\"tranches\",\"tranch\",\"moyenne\",\"durs\",\"pincer\",\"refroidi\",\"refroidie\",\"grande\",\"pot\",\"emballée\",\"poche\",\"paquet\",\"ordinaire\",\"bandes\",\"chaude\",\"chaudes\",\"plus\",\"coupées\",\"lanières\",\"moitié\",\"cuillères à thé\",\"en\",\"cubes\",\"cube\",\"dénoyauté\",\"dénoyautés\",\"mince\",\"minces\",\"tout petit\",\"pelée\",\"pelées\",\"rôti\",\"rôtis\",]\n",
    "    units = [\" onces \",\" ml \", \" l \",\" g \",\" kg \",\" kgs \",\" oz \",\" cm \",\" tasse de \"]\n",
    "    units_remove = ['%','/','.','-','_','-',']','*','-/', 'c.',\"[,\",\"]\",\"onces\",\"ml\", \"l\",\"g\",\"kg\",\"kgs\",\"oz\",\"cm\"]\n",
    "\n",
    "    for result in data['data']:\n",
    "        d= result[u'ingredients'][u'non classés'][u'list']\n",
    "        for a in d:\n",
    "            m= a['description']\n",
    "\n",
    "            rgx = recompile(r'(?<=\\d)[,](?=\\d)')\n",
    "            m = rgx.sub(\".\",m)\n",
    "            m =re.sub(\"d'\",\"de \",m)\n",
    "            word_tokens = word_tokenize(m) \n",
    "            m  = (\" \").join(word_tokens)\n",
    "            m = re.sub(\"\\. \",\" \",m)\n",
    "            split_string1 = m.split(',')\n",
    "            if \", \" in m:\n",
    "                if split_string1[1].strip() == \"sans peau\":\n",
    "                    \n",
    "                    substring2 = split_string1[0] +\", \"+split_string1[1]\n",
    "                else:\n",
    "                    substring2 = split_string1[0]         \n",
    "            else:\n",
    "                substring2 = m \n",
    "            if split_string1[0] == \"6 tranches \":\n",
    "                substring2 = split_string1[1]\n",
    "            split_string = substring2.split(' ou ')\n",
    "            substring1 = \"\"\n",
    "            substring1 = split_string[0]\n",
    "            substring1 = substring1.lower()\n",
    "            \n",
    "            index = 0\n",
    "            u = \"x\"\n",
    "            for x in units:\n",
    "                finding = max(substring1.find(x),0)\n",
    "                if finding > index:\n",
    "                  index =finding\n",
    "                  u = x\n",
    "            if u == \"x\" and a['unit'] != None:\n",
    "                u = a['unit']\n",
    "            \n",
    "\n",
    "            s = substring1\n",
    "            pattern1 = r\"(\\d+){}\".format(u)\n",
    "            pattern2 = r\"(\\d+/\\d+){}\".format(u)\n",
    "            pattern3 = r\"(\\d+.\\d+){}\".format(u)\n",
    "\n",
    "            if len(re.findall(pattern2, s))>0:\n",
    "                quantity_product = re.findall(pattern2, s)[0]\n",
    "\n",
    "            elif len(re.findall(pattern1, s))>0:\n",
    "                if len(re.findall(pattern3, s))>0:\n",
    "                    quantity_product = re.findall(pattern3, s)[0]\n",
    "\n",
    "                else:\n",
    "                    quantity_product = re.findall(pattern1, s)[0]\n",
    "            else:\n",
    "                quantity_product = a['quantity']\n",
    "                \n",
    "            if index !=0:\n",
    "                index = index + len(u.strip())+1\n",
    "\n",
    "            substring3 = substring1\n",
    "            substring3 = re.sub(\"\\(.*?\\)\",\"\",substring3)\n",
    "            \n",
    "            index = [i for i in range(len(substring3)) if substring3.startswith(\"(\", i)]\n",
    "\n",
    "            if len(index) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                index = index[0]\n",
    "                substring3 = substring3[:index]  \n",
    "\n",
    "\n",
    "            index = [i for i in range(len(substring3)) if substring3.startswith(\")\", i)]\n",
    "\n",
    "            if len(index) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                index = index[-1]\n",
    "                substring3 = substring3[index+1:]      \n",
    "            x = re.findall(\"\\d\", substring3)\n",
    "\n",
    "            for aaa in set(x):\n",
    "                substring3 = re.sub(aaa,\"\",substring3)\n",
    "            substring4 = substring3\n",
    "            word_tokens = word_tokenize(substring4) \n",
    "            \n",
    "            \n",
    "            substring4 = singularize(substring4)\n",
    "            filtered_sentence = [w for w in word_tokens if not w.strip() in unknow_words+units_remove] \n",
    "            substring4  = (\" \").join(filtered_sentence)\n",
    "\n",
    "            substring4 = substring4.strip(\",\")\n",
    "            substring4 = substring4.strip()\n",
    "            substring4 = re.sub(\"-\",\"\",substring4)\n",
    "\n",
    "            u = u.strip()\n",
    "            try:\n",
    "                quantity_product =float(quantity_product)\n",
    "                if u == 'litres' or u == 'litre' or u == \"liter\" or u == \"liters\" or u == \"ml\" or u == \"l\":\n",
    "                    if u == \"ml\":\n",
    "                        quantity_product = quantity_product/1000\n",
    "                    u=\"l\"\n",
    "                elif u == \"kgs\" or u == \"kg\" or u == \"g\":\n",
    "                    if u == \"g\":\n",
    "                        quantity_product = quantity_product/1000\n",
    "                    u=\"kg\"\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            output_converter = convert_unit(substring4,u,quantity_product,ml,gram,m)\n",
    "\n",
    "            quantity_product,u = output_converter[0],output_converter[1]\n",
    "\n",
    "            des.append(substring4)\n",
    "            quantity.append(quantity_product)\n",
    "            unit.append(u)\n",
    "            df =pd.DataFrame(zip(des,quantity,unit),columns=[\"food\",\"quantity\",\"unit\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_category_list():\n",
    "  bakery = []\n",
    "  with open(\"categories_data/Boulangerie.txt\") as f:\n",
    "    bakery = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "  chilled = []\n",
    "  with open(\"categories_data/Chilled_2.txt\") as f:\n",
    "    chilled = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "  beverages = []\n",
    "  with open(\"categories_data/Breuvages.txt\") as f:\n",
    "    beverages = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "  dairy = []\n",
    "  with open(\"categories_data/produits_laitiers_et_œufs.txt\") as f:\n",
    "    dairy = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "  fruit = []\n",
    "  with open(\"categories_data/fruits_et_légumes.txt\") as f:\n",
    "    fruit = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "  grains = []\n",
    "  with open(\"categories_data/céréales_et_haricots.txt\") as f:\n",
    "    grains = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "  herbs = []\n",
    "  with open(\"categories_data/herbes_et_épices.txt\") as f:\n",
    "    herbs = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "  meat = []\n",
    "  with open(\"categories_data/viande_poisson_et_substituts.txt\") as f:\n",
    "    meat = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "    \n",
    "  nuts = []\n",
    "  with open(\"categories_data/noix_et_graines.txt\") as f:\n",
    "    nuts = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "    \n",
    "  pantry = []\n",
    "  with open(\"categories_data/garde-manger.txt\") as f:\n",
    "    pantry = [add_spaces(singularize(re.sub(\"\\n\",\"\",a).strip())) for a in f.readlines() if len(a)>0]\n",
    "\n",
    "  return bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spaces(text):\n",
    "    return \" \"+text+\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_cat(name,bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry):\n",
    "  \n",
    "  for a in bakery:\n",
    "    if a in name and len(a)>0:\n",
    "      return 0\n",
    "\n",
    "  for a in chilled:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 1\n",
    "\n",
    "  for a in beverages:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 2\n",
    "\n",
    "  for a in dairy:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 3\n",
    "\n",
    "  for a in fruit:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 4\n",
    "\n",
    "  for a in grains:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 5\n",
    "\n",
    "  for a in herbs:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 6\n",
    "\n",
    "  for a in meat:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 7\n",
    "\n",
    "  for a in nuts:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 8\n",
    "\n",
    "  for a in pantry:\n",
    "    if a.lower() in name.lower() and len(a)>0:\n",
    "      return 9\n",
    "\n",
    "  return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(input_json):\n",
    "    ml,gram = read_units()\n",
    "    df = process(input_json,ml,gram)\n",
    "    df1 = df.groupby([\"food\",\"unit\"])\n",
    "    bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry = create_category_list()\n",
    "    json_bakery = []\n",
    "    json_chilled = []\n",
    "    json_beverages=[] \n",
    "    json_dairy =[] \n",
    "    json_fruit=[]\n",
    "    json_grains =[] \n",
    "    json_herbs = []\n",
    "    json_meat =[]\n",
    "    json_nuts =[]\n",
    "    json_pantry =[]\n",
    "    json_others = []\n",
    "    for name,group in df1:\n",
    "        new = {}\n",
    "        new[\"ingredient\"]=name[0]\n",
    "        try:\n",
    "            if name[1] == \"l\" and group[\"quantity\"].sum()<1:\n",
    "                new[\"unit\"]=\"ml\"\n",
    "                new[\"quantity\"]=float(group[\"quantity\"].sum()*1000)\n",
    "            elif name[1] ==\"kg\" and group[\"quantity\"].sum()<1:\n",
    "                new[\"unit\"]=\"g\"\n",
    "                new[\"quantity\"]=float(group[\"quantity\"].sum()*1000)\n",
    "            else:\n",
    "                new[\"unit\"]=name[1]\n",
    "                if round(group[\"quantity\"].sum(),2) == int(group[\"quantity\"].sum())+0.99:\n",
    "                    new[\"quantity\"] = round(group[\"quantity\"].sum(),0)\n",
    "                else:\n",
    "                    new[\"quantity\"]=round(group[\"quantity\"].sum(),2)\n",
    "        except:\n",
    "            \n",
    "            new[\"unit\"]=name[1]\n",
    "            total = 0\n",
    "            \n",
    "            for qw in group[\"quantity\"]:\n",
    "                a = qw.split(\"/\")\n",
    "                \n",
    "                a1 = int(a[0])\n",
    "                a2 = int(a[1])\n",
    "                total = total + a1/a2\n",
    "                \n",
    "            if round(total,2) == 0.33:\n",
    "                quantity = \"1/3\"\n",
    "            else:\n",
    "                out = (total).as_integer_ratio()\n",
    "                quantity = str(out[0])+\"/\"+str(out[1])\n",
    "                if out[0] == out[1]:\n",
    "                    quantity = out[0]\n",
    "            \n",
    "            new[\"quantity\"] = quantity\n",
    "        cat = name_cat(add_spaces(name[0]),bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry) \n",
    "        if cat == 0:\n",
    "            json_bakery.append(new)\n",
    "        elif cat == 1:\n",
    "            json_chilled.append(new)\n",
    "        elif cat == 2:\n",
    "            json_beverages.append(new)\n",
    "        elif cat == 3:\n",
    "            json_dairy.append(new)\n",
    "        elif cat == 4:\n",
    "            json_fruit.append(new)\n",
    "        elif cat == 5:\n",
    "            json_grains.append(new)\n",
    "        elif cat == 6:\n",
    "            json_herbs.append(new)\n",
    "        elif cat == 7:\n",
    "            json_meat.append(new)\n",
    "        elif cat == 8:\n",
    "            json_nuts.append(new)\n",
    "        elif cat == 9:\n",
    "            json_pantry.append(new)\n",
    "        elif cat == 10:\n",
    "            json_others.append(new)\n",
    "\n",
    "\n",
    "    final = {\"garde manger\":json_pantry,\"Breuvages\":json_beverages,\"fruits et légumes\":json_fruit,\n",
    "            \"viande poisson et substituts\":json_meat,\"produits laitiers et œufs\":json_dairy,\n",
    "             \"Chilled\":json_chilled,\"céréales et haricots\":json_grains,\"herbes et épices\":json_herbs,\n",
    "            \"noix et graines\":json_nuts,\"Boulangerie\":json_bakery,\"Vous pourriez également avoir besoin\":json_others}\n",
    "    \n",
    "    \n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "f = open('total_french.json',encoding=\"utf-8\")\n",
    "data = json.load(f)\n",
    "aa = main_function(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.json\", \"w\",encoding=\"utf-8\") as outfile: \n",
    "    json.dump(aa, outfile,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "food_extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
