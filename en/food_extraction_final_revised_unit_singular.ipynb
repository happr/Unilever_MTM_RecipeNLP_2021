{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l7ED8jpSDZeb"
   },
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import RegexpParser\n",
    "from nltk import Tree\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# all the packages we need to download.\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0K8y2Ho7dJK8"
   },
   "outputs": [],
   "source": [
    "# A function to return the tags of a sentence. Tags such as noun verb or else. The tags are used to find patterns\n",
    "def preprocess1(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function which reads in the unit file and convert all the data into list so we can use them to change\n",
    "# the units of ingredient. To add more unit list we have to modify this function and read the additional file of unit\n",
    "# as well.\n",
    "# We are lemmatizing and cleaning the file data as well to synchronize it with our processing and so \n",
    "#  Mango and mango are not taken as separate ones.\n",
    "def read_units():\n",
    "    ml=[]\n",
    "    with open(\"units_data/ml.txt\") as f:\n",
    "        ml =[wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower()) for a in f.readlines()]\n",
    "    \n",
    "    gram = []\n",
    "    with open(\"units_data/gram.txt\") as f:\n",
    "        gram = [wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower()) for a in f.readlines()]\n",
    "\n",
    "    return ml,gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a case is better understand by an example. We have an ingredient water whose unit we are forcing to be ml.\n",
    "# Now in one of the ingredient water is coming as 1/2 cups. We simply force it to be 1/2 ml but when we have to add\n",
    "# this with other ml of water like we might have 2 ml water, adding 1/2 and 2 is not possible in python as 1/2 is \n",
    "# consider a string. So we need to convert 1/2 into 0.5. so this function does that.\n",
    "def divider(number):\n",
    "    a_q = number.split(\"/\")\n",
    "    a1 = int(a_q[0])\n",
    "    a2 = int(a_q[1])\n",
    "    return a1/a2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function which covnerts the ingredient unit according to the file we have created. This function recieves\n",
    "# those list as shown by ml and gram parameter and they also takes the ingredient name, unit and quantity.\n",
    "# The major functionality is to check the name and if the name lies in the list, it converts it. The issue was\n",
    "#  occuring that if the ingredient is in l we should convert that to kg and not g so we need to check that as well\n",
    "# and because of that we have the quantity with us as well.\n",
    "def convert_unit(substring4,unit,quantity_product,ml,gram):\n",
    "    for m in ml:\n",
    "        if m in substring4 and len(m)>0 and unit !=\"l\":\n",
    "            try:\n",
    "                if unit == \"kg\":\n",
    "                    return quantity_product,\"l\"\n",
    "                else:\n",
    "                    return quantity_product/1000,\"l\"\n",
    "            except:\n",
    "                \n",
    "                return divider(quantity_product)/1000,\"l\"\n",
    "    for g in gram:\n",
    "        if g in substring4 and len(g)>0 and unit !=\"kg\":\n",
    "            try:\n",
    "                if unit == \"l\":\n",
    "                    return quantity_product,\"kg\"\n",
    "                else:\n",
    "                    return quantity_product/1000,\"kg\"\n",
    "            except:\n",
    "                return divider(quantity_product)/1000,\"kg\"\n",
    "            \n",
    "    return quantity_product,unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pattern thats found in the ingredient listing is that words after a comma is mostly attributes of ingredient\n",
    "# which is not required by us. so we remove that by spliting. This case fails few time and we recognize them by \n",
    "# pos tags. If certain tag exists around the , we don't split it. The \n",
    "def comma_separator(m):\n",
    "    split_string1 = m.split(',')\n",
    "\n",
    "    done = 0\n",
    "    if \",\" in m:\n",
    "        patterns1 = \"\"\"P: {<NN><,><NN>}\n",
    "                        {<VBD><,><VBD>}\n",
    "                        {<JJ><,><JJ>}    \n",
    "                        {<VBN><,><VBN>}\"\"\"  \n",
    "        PChunker1 = RegexpParser(patterns1)\n",
    "        output_pattern1 = PChunker1.parse(preprocess1(m))\n",
    "        for child in output_pattern1:\n",
    "            if isinstance(child, Tree):              \n",
    "                if child.label() == 'P':\n",
    "\n",
    "                    if (child[0][1] == \"VBD\") and len(split_string1)<3:\n",
    "                        done=1\n",
    "                        substring2 = split_string1[0] + \",\" +split_string1[1]\n",
    "                    elif child[0][1] == \"NN\" or child[0][1] == \"VBN\" or child[0][1] == \"JJ\":\n",
    "                        done=1\n",
    "                        substring2 = split_string1[0] + \",\" +split_string1[1]\n",
    "    if done == 0:\n",
    "        substring2 = split_string1[0]     \n",
    "    return substring2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is same as comma separator, we didn't require the text which comes after or except for few places which we \n",
    "# catch using pos tags pattern. There was some and/or in the text which needed to be converted so first we did that.\n",
    "# in patterns you can see all the pos tag pattern on which we have to keep the both side of the or's.\n",
    "\n",
    "def or_separator(substring2):\n",
    "    substring2 = re.sub(\"and/or\",\"or\",substring2)\n",
    "    substring2 = re.sub(\"or/and\",\"or\",substring2)\n",
    "    split_string = substring2.split(' or ')\n",
    "    substring1 = \"\"\n",
    "\n",
    "    done = 0\n",
    "    patterns = \"\"\"P: {<JJ><CC><JJ>}\n",
    "                     {<VBD><CC><VB>}\n",
    "                     {<NN><CC><JJ>}\n",
    "                     {<VBD><CC><JJ>}\n",
    "                     {<CD><CC><CD>}\"\"\" \n",
    "    PChunker = RegexpParser(patterns)\n",
    "    if \" or \" in substring2:\n",
    "        found_pat = PChunker.parse(preprocess1(substring2))\n",
    "\n",
    "        for child in found_pat:\n",
    "            if isinstance(child, Tree):               \n",
    "                if child.label() == 'P':\n",
    "                    if child[1][0] == \"or\":\n",
    "                        done=1\n",
    "\n",
    "                        substring1 = split_string[1]\n",
    "\n",
    "    if done ==0:\n",
    "        substring1 = split_string[0]\n",
    "        \n",
    "    return substring1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "t9xMMGNO7m0E"
   },
   "outputs": [],
   "source": [
    "# Main function that processes all and return the dataframe having all ingredients with there quantity and unit.\n",
    "# it takes in the json data with the ml and gram unit lists as well. \n",
    "def process(input_json_data,ml,gram):\n",
    "\n",
    "    data = input_json_data\n",
    "    df = None\n",
    "    des,quantity,unit = [],[],[]\n",
    "    \n",
    "#     The bigram words we want to remove from the text\n",
    "    bigram = [\"seasoned dry\"]\n",
    "#     THe one gram words we want to remove from the text\n",
    "    unknow_words = [\"assorted\",\"free-range\",\"hard\",\"hard-cooked\",\"added\",\"no-salt\",'chopped',\"slices\",\"pinch\",\"large\",\"medium\",\"small\",\"each\",\"cooked\",\"uncooked\",\"cooled\",\"pot\", \"pouch\", \"packed\" ,\"package\", \"regular\", \"roughly\" ,\"slice\", \"sliced\", \"strips\"]\n",
    "#     THe units we may encounter in our ingredients\n",
    "    units = [' ml ', ' cup ',' can ',' cans ',' litres ',' litre ', ' cups ',\" liter \",\" liters \", \" cm \",\" in \",' g ', ' oz ',' lb ', ' kg ',' kgs ', ' cm ', ' tbsp ', \" ounces \",\" lbs \",' tsp ', ' l ']\n",
    "#     The other small things and issues we need to remove which where no useful\n",
    "    units_remove = ['%','/','.','-','_',']','*','-/', 'c.', 'à', 'thé','hot','pkg','plus','tbsp/','litres','litre','half','and','cubed','cube', '/-inch', \"in\",\"cm\",',packages', 'pitted', 'plain' ,'thin' ,'ea','-inch' ,'inch' ,'cube', 'cubes','thinly','tiny','finely','[','ml', 'cup',\"cups\",'can','cans', \"liter\",\"-in\",\"liters\", 'g', 'oz', 'kg', 'cm','lb','-lb' ,'tbsp', 'kgs','tsp', 'l',\"ea\",\"ounces\",\"lbs\",\"peeled\",\"roasted\"]\n",
    "\n",
    "#     looping over the data\n",
    "    for result in data['data']:\n",
    "#         Picking all the ingredients in a reciepe and then we loop over it as well\n",
    "        d= result[u'ingredients'][u'ungrouped'][u'list']\n",
    "        for a in d:\n",
    "#             Storing the units\n",
    "            actual_unit = a['unit']\n",
    "#             Storing the ingredient\n",
    "            m= a['description']\n",
    "\n",
    "#             Removing extra . like at places it was 1 g. water but we need 1 g water so doing that\n",
    "            m = re.sub(\"g\\.\",\"g\",m)\n",
    "            m = re.sub(\"\\. \",\" \",m)\n",
    "#             Tokenization means converting the sentence into words\n",
    "            word_tokens = word_tokenize(m) \n",
    "#             Then re joining them to form a sentence again. The usefulness of this step is that it will add \n",
    "#             spaces with every word and punctuation\n",
    "            m  = (\" \").join(word_tokens)\n",
    "            \n",
    "#         calling the comma separator\n",
    "            substring2 = comma_separator(m)\n",
    "#     calling the or separator\n",
    "            substring1 = or_separator(substring2)\n",
    "\n",
    "#     Lowering the text so English and english becomes same and not different\n",
    "            substring1 = substring1.lower()\n",
    "    \n",
    "#     This portion is for deciding the unit of ingredient.it has multiple steps to check the units\n",
    "#     it checks if any of the unit exists in the ingredient from the list we created above. The last unit is \n",
    "#     preferred over everybody else. If the unit within string and in attributes matches that unit is finalized\n",
    "#     without looking for other units\n",
    "#     if no unit was found the attribute unit is assigned and even if that is empty x is assigned to it\n",
    "            index = 0\n",
    "            u = \"x\"\n",
    "            for x in units:\n",
    "                finding = max(substring1.find(x),0)\n",
    "                if finding > index:\n",
    "                  index =finding\n",
    "                  u = x\n",
    "                  if actual_unit != None and u.strip() == actual_unit.strip():\n",
    "                      break\n",
    "                    \n",
    "            if u == \"x\" and a['unit'] != None:\n",
    "                u = a['unit']\n",
    "            \n",
    "\n",
    "# From here the quantity extraction process starts. We want the quantity that comes before our selected unit.\n",
    "# To do that we do the pattern match and pick the number before the unit.\n",
    "# there are different ways how a number can be listed so we need to check pattern for all.\n",
    "#  1/2 , 0/5,4 are different styles of quantity.\n",
    "\n",
    "# After checking the pattern we extract that quantity and is stored. If no quantity is found we go to the quantity\n",
    "# attribute\n",
    "            s = substring1\n",
    "            pattern1 = r\"(\\d+){}\".format(u)\n",
    "            pattern2 = r\"(\\d+/\\d+){}\".format(u)\n",
    "            pattern3 = r\"(\\d+.\\d+){}\".format(u)\n",
    "\n",
    "            if len(re.findall(pattern2, s))>0:\n",
    "                quantity_product = re.findall(pattern2, s)[0]\n",
    "\n",
    "            elif len(re.findall(pattern1, s))>0:\n",
    "                if len(re.findall(pattern3, s))>0:\n",
    "                    quantity_product = re.findall(pattern3, s)[0]\n",
    "\n",
    "                else:\n",
    "                    quantity_product = re.findall(pattern1, s)[0]\n",
    "            else:\n",
    "                quantity_product = a['quantity']\n",
    "                \n",
    "            if index !=0:\n",
    "                index = index + len(u.strip())+1\n",
    "            \n",
    "\n",
    "# removing the brackets and text inside brackets\n",
    "            substring3 = substring1\n",
    "            substring3 = re.sub(\"\\(.*?\\)\",\"\",substring3)\n",
    "            \n",
    "            \n",
    "            index = [i for i in range(len(substring3)) if substring3.startswith(\"(\", i)]\n",
    "\n",
    "            if len(index) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                index = index[0]\n",
    "                substring3 = substring3[:index]  \n",
    "\n",
    "\n",
    "            index = [i for i in range(len(substring3)) if substring3.startswith(\")\", i)]\n",
    "\n",
    "            if len(index) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                index = index[-1]\n",
    "                substring3 = substring3[index+1:]      \n",
    "            x = re.findall(\"\\d\", substring3)\n",
    "\n",
    "# here we are removing all extra numbers inside an ingredient \n",
    "            for aaa in set(x):\n",
    "                substring3 = re.sub(aaa,\"\",substring3)\n",
    "            substring4 = substring3\n",
    "            \n",
    "#             tokenizing and removing all bigrams word according to the list we created above. We are also doing\n",
    "# lemmatization which singularize the words\n",
    "            word_tokens = word_tokenize(substring4) \n",
    "            filtered_sentence = [wnl.lemmatize(w) for w in word_tokens if not w in unknow_words+units_remove] \n",
    "            substring4  = (\" \").join(filtered_sentence)\n",
    "\n",
    "\n",
    "#             basic striping and cleaning\n",
    "            substring4 = substring4.strip(\",\")\n",
    "            substring4 = substring4.strip()\n",
    "             \n",
    "            u = u.strip()\n",
    "            \n",
    "#       now the portion for quantity conversion starts. We wanted to convert all the different variants of liters and\n",
    "#      kgs to be one so we do that here. if its in ml or g we also divide it by 1000 to make it equal to kg\n",
    "            try:\n",
    "                quantity_product =float(quantity_product)\n",
    "                if u == 'litres' or u == 'litre' or u == \"liter\" or u == \"liters\" or u == \"ml\" or u == \"l\":\n",
    "                    if u == \"ml\":\n",
    "                        quantity_product = quantity_product/1000\n",
    "                    u=\"l\"\n",
    "                elif u == \"kgs\" or u == \"kg\" or u == \"g\":\n",
    "                    if u == \"g\":\n",
    "                        quantity_product = quantity_product/1000\n",
    "                    u=\"kg\"\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "# bigram word removal\n",
    "            for bi in bigram:\n",
    "                if bi in substring4:\n",
    "                    substring4 = re.sub(bi,\"\",substring4)\n",
    "            \n",
    "#             converting the unit. first we synchronize the unit one step back and now we want to convert them.\n",
    "#          we simply call the function we created with the list and it will get us the results\n",
    "            output_converter = convert_unit(substring4,u,quantity_product,ml,gram)\n",
    "\n",
    "            quantity_product,u = output_converter[0],output_converter[1]\n",
    "\n",
    "            if \"cut-up\" in substring4:\n",
    "                print(m)\n",
    "                print(substring4)\n",
    "#         now after everything is processing we convert them to form a dataframe and return the info for further process\n",
    "            des.append(substring4)\n",
    "            quantity.append(quantity_product)\n",
    "            unit.append(u)\n",
    "            df =pd.DataFrame(zip(des,quantity,unit),columns=[\"food\",\"quantity\",\"unit\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function adds spaces before and after a word. This was required due to certain issues.\n",
    "# eg we want to find the category of rice which is listed in I think pantry. We also have ice listed in chilled. \n",
    "# now when we try to match ice with rice it give 100% match as ice is there in rice and we dont want that. so we added\n",
    "# spaces this covnerted the \"ice\" into \" ice \" which is not present in \"rice \"\n",
    "def add_spaces(text):\n",
    "    return \" \"+text+\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "k4pUZWr4LcnT"
   },
   "outputs": [],
   "source": [
    "# reading all the category files cleaning them and creating there lists for checking\n",
    "def create_category_list():\n",
    "  bakery = []\n",
    "  with open(\"categories_data/Bakery.txt\") as f:\n",
    "    bakery = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  chilled = []\n",
    "  with open(\"categories_data/Chilled.txt\") as f:\n",
    "    chilled = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  beverages = []\n",
    "  with open(\"categories_data/Beverages.txt\") as f:\n",
    "    beverages = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  dairy = []\n",
    "  with open(\"categories_data/Dairy_Eggs.txt\") as f:\n",
    "    dairy = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  fruit = []\n",
    "  with open(\"categories_data/Fruit_Vegetables.txt\") as f:\n",
    "    fruit = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  grains = []\n",
    "  with open(\"categories_data/Grains_Beans.txt\") as f:\n",
    "    grains = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  herbs = []\n",
    "  with open(\"categories_data/Herbs_Spices.txt\") as f:\n",
    "    herbs = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  meat = []\n",
    "  with open(\"categories_data/Meat_Fish _Alternatives.txt\") as f:\n",
    "    meat = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "    \n",
    "  nuts = []\n",
    "  with open(\"categories_data/Nuts_Seeds.txt\") as f:\n",
    "    nuts =[add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "    \n",
    "  pantry = []\n",
    "  with open(\"categories_data/Pantry.txt\") as f:\n",
    "    pantry = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  return bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "g8pm-4xALcnU"
   },
   "outputs": [],
   "source": [
    "# this function takes in all the list and the ingredient name and return its category\n",
    "def name_cat(name,bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry):\n",
    "  for a in bakery:\n",
    "    if a in name and len(a)>0:\n",
    "      return 0\n",
    "\n",
    "  for a in chilled:\n",
    "    if a in name and len(a)>0:\n",
    "      return 1\n",
    "\n",
    "  for a in beverages:\n",
    "    if a in name and len(a)>0:\n",
    "      return 2\n",
    "\n",
    "  for a in dairy:\n",
    "    if a in name and len(a)>0:\n",
    "      return 3\n",
    "\n",
    "  for a in fruit:\n",
    "    if a in name and len(a)>0:\n",
    "      return 4\n",
    "\n",
    "  for a in grains:\n",
    "    if a in name and len(a)>0:\n",
    "      return 5\n",
    "\n",
    "  for a in herbs:\n",
    "    if a in name and len(a)>0:\n",
    "      return 6\n",
    "\n",
    "  for a in meat:\n",
    "    if a in name and len(a)>0:\n",
    "      return 7\n",
    "\n",
    "  for a in nuts:\n",
    "    if a in name and len(a)>0:\n",
    "      return 8\n",
    "\n",
    "  for a in pantry:\n",
    "    if a in name and len(a)>0:\n",
    "      return 9\n",
    "\n",
    "  return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TS9wwV9bN9Dy"
   },
   "outputs": [],
   "source": [
    "# the main function that calls all the functions and synchronize everything. It only takes in the data\n",
    "def main_function(input_json):\n",
    "    \n",
    "#     Calling the function which reads the unit files\n",
    "    ml,gram = read_units()\n",
    "#     doing the main process and getting the dataframe\n",
    "    df = process(input_json,ml,gram)\n",
    "#     grouping them as to calculate the total quantity of each unique product\n",
    "    df1 = df.groupby([\"food\",\"unit\"])\n",
    "#     reading all the unit files\n",
    "    bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry = create_category_list()\n",
    "    \n",
    "#     creating lists to store the ingredients under each category\n",
    "    json_bakery = []\n",
    "    json_chilled = []\n",
    "    json_beverages=[] \n",
    "    json_dairy =[] \n",
    "    json_fruit=[]\n",
    "    json_grains =[] \n",
    "    json_herbs = []\n",
    "    json_meat =[]\n",
    "    json_nuts =[]\n",
    "    json_pantry =[]\n",
    "    json_others = []\n",
    "#     looping over the grouped dataframe to clean and store it.\n",
    "    for name,group in df1:\n",
    "        new = {}\n",
    "        new[\"ingredient\"]=name[0].strip()\n",
    "#         this logic supports the idea that if we have quantity less then 1 l it should be in ml. so this code snippet\n",
    "# does that with kg and l. it convertes the quantity and unit if less then 1. It then round it to 2 digits. \n",
    "# it also supports the idea that if we have a quantity 2.99999, it should get 3 rather then 2.99.\n",
    "        try:\n",
    "            if name[1] == \"l\" and group[\"quantity\"].sum()<1:\n",
    "                new[\"unit\"]=\"ml\"\n",
    "                new[\"quantity\"]=round(float(group[\"quantity\"].sum()*1000),2)\n",
    "            elif name[1] ==\"kg\" and group[\"quantity\"].sum()<1:\n",
    "                new[\"unit\"]=\"g\"\n",
    "                new[\"quantity\"]=round(float(group[\"quantity\"].sum()*1000),2)\n",
    "            else:\n",
    "                new[\"unit\"]=name[1]\n",
    "                if round(group[\"quantity\"].sum(),2) == int(group[\"quantity\"].sum())+0.99:\n",
    "                    new[\"quantity\"] = round(group[\"quantity\"].sum(),0)\n",
    "                else:\n",
    "                    new[\"quantity\"]=round(group[\"quantity\"].sum(),2)\n",
    "        except:\n",
    "#             we were having issues with quantity 1/2 so this code deal with that.\n",
    "            new[\"unit\"]=name[1]\n",
    "            total = 0\n",
    "            \n",
    "            for qw in group[\"quantity\"]:\n",
    "                a = qw.split(\"/\")\n",
    "                \n",
    "                a1 = int(a[0])\n",
    "                a2 = int(a[1])\n",
    "                total = total + a1/a2\n",
    "                \n",
    "            if round(total,2) == 0.33:\n",
    "                quantity = \"1/3\"\n",
    "            else:\n",
    "                out = (total).as_integer_ratio()\n",
    "                quantity = str(out[0])+\"/\"+str(out[1])\n",
    "                if out[0] == out[1]:\n",
    "                    quantity = out[0]\n",
    "            \n",
    "            new[\"quantity\"] = quantity\n",
    "# getting the category name by calling the function\n",
    "        cat = name_cat(add_spaces(name[0]),bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry) \n",
    "        \n",
    "#         according to category name adding the info in that list created above\n",
    "        if cat == 0:\n",
    "            json_bakery.append(new)\n",
    "        elif cat == 1:\n",
    "            json_chilled.append(new)\n",
    "        elif cat == 2:\n",
    "            json_beverages.append(new)\n",
    "        elif cat == 3:\n",
    "            json_dairy.append(new)\n",
    "        elif cat == 4:\n",
    "            json_fruit.append(new)\n",
    "        elif cat == 5:\n",
    "            json_grains.append(new)\n",
    "        elif cat == 6:\n",
    "            json_herbs.append(new)\n",
    "        elif cat == 7:\n",
    "            json_meat.append(new)\n",
    "        elif cat == 8:\n",
    "            json_nuts.append(new)\n",
    "        elif cat == 9:\n",
    "            json_pantry.append(new)\n",
    "        elif cat == 10:\n",
    "            json_others.append(new)\n",
    "\n",
    "\n",
    "# sending the final output that is recieved by the front end. \n",
    "    final = {\"Pantry\":json_pantry,\"Beverages\":json_beverages,\"Fruits and Vegetables\":json_fruit,\n",
    "             \"Meat,Fish and Alternatives\":json_meat,\"Dairy and Eggs\":json_dairy,\n",
    "             \"Chilled\":json_chilled,\"Grains and Beans\":json_grains,\"Herbs and Spices\":json_herbs,\n",
    "             \"Nuts and Seeds\":json_nuts,\"Bakery\":json_bakery,\"You may also need\":json_others}\n",
    "    return final\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 cups ( 750 mL ) cut-up , cooked or canned chicken\n",
      "cut-up\n",
      "2 cups ( 450 mL ) cut-up cooked chicken\n",
      "cut-up chicken\n",
      "1 cup ( 250 mL ) cut-up deli ham and/or cooked chicken\n",
      "cut-up deli ham\n",
      "2 cups ( 500 mL ) cut-up cooked rotisserie chicken\n",
      "cut-up rotisserie chicken\n",
      "2 cups ( 500 mL ) cut-up cooked chicken\n",
      "cut-up chicken\n",
      "1/3 cup ( 75 mL ) cut-up apple or grapes\n",
      "cut-up apple\n",
      "4 cups ( 1 L ) cut-up assorted fresh vegetables , ( bell peppers , mushrooms , zucchini and/or yellow squash )\n",
      "cut-up fresh vegetable\n",
      "2 cups ( 500 mL ) assorted cut-up fresh vegetables , ( broccoli florets , red bell pepper , zucchini and/or asparagus )\n",
      "cut-up fresh vegetable\n",
      "2 cups ( 500 mL ) rotisserie chicken or cut-up cooked chicken\n",
      "cut-up chicken\n",
      "1 cup ( 250 mL ) cut-up cooked chicken , cubed\n",
      "cut-up chicken\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "f = open('total.json')\n",
    "data = json.load(f)\n",
    "aa = main_function(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.json\", \"w\",encoding=\"utf-8\") as outfile: \n",
    "    json.dump(aa, outfile,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "food_extraction_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
