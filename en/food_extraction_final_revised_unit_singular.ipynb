{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l7ED8jpSDZeb"
   },
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import RegexpParser\n",
    "from nltk import Tree\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0K8y2Ho7dJK8"
   },
   "outputs": [],
   "source": [
    "def preprocess1(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_units():\n",
    "    ml=[]\n",
    "    with open(\"units_data/ml.txt\") as f:\n",
    "        ml =[wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower()) for a in f.readlines()]\n",
    "    \n",
    "    gram = []\n",
    "    with open(\"units_data/gram.txt\") as f:\n",
    "        gram = [wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower()) for a in f.readlines()]\n",
    "\n",
    "    return ml,gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divider(number):\n",
    "    a_q = number.split(\"/\")\n",
    "    a1 = int(a_q[0])\n",
    "    a2 = int(a_q[1])\n",
    "    return a1/a2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unit(substring4,unit,quantity_product,ml,gram):\n",
    "    for m in ml:\n",
    "        if m in substring4 and len(m)>0 and unit !=\"l\":\n",
    "            try:\n",
    "                if unit == \"kg\":\n",
    "                    return quantity_product,\"l\"\n",
    "                else:\n",
    "                    return quantity_product/1000,\"l\"\n",
    "            except:\n",
    "                \n",
    "                return divider(quantity_product)/1000,\"l\"\n",
    "    for g in gram:\n",
    "        if g in substring4 and len(g)>0 and unit !=\"kg\":\n",
    "            try:\n",
    "                if unit == \"l\":\n",
    "                    return quantity_product,\"kg\"\n",
    "                else:\n",
    "                    return quantity_product/1000,\"kg\"\n",
    "            except:\n",
    "                return divider(quantity_product)/1000,\"kg\"\n",
    "            \n",
    "    return quantity_product,unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "t9xMMGNO7m0E"
   },
   "outputs": [],
   "source": [
    "def process(input_json_data,ml,gram):\n",
    "\n",
    "    data = input_json_data\n",
    "    df = None\n",
    "    des,quantity,unit = [],[],[]\n",
    "    bigram = [\"seasoned dry\"]\n",
    "    unknow_words = [\"assorted\",\"free-range\",\"hard\",\"hard-cooked\",\"added\",\"no-salt\",'chopped',\"slices\",\"pinch\",\"large\",\"medium\",\"small\",\"each\",\"cooked\",\"uncooked\",\"cooled\",\"pot\", \"pouch\", \"packed\" ,\"package\", \"regular\", \"roughly\" ,\"slice\", \"sliced\", \"strips\"]\n",
    "    units = [' ml ', ' cup ',' can ',' cans ',' litres ',' litre ', ' cups ',\" liter \",\" liters \", \" cm \",\" in \",' g ', ' oz ',' lb ', ' kg ',' kgs ', ' cm ', ' tbsp ', \" ounces \",\" lbs \",' tsp ', ' l ']\n",
    "    units_remove = ['%','/','.','-','_',']','*','-/', 'c.', 'à', 'thé','hot','pkg','plus','tbsp/','litres','litre','half','and','cubed','cube', '/-inch', \"in\",\"cm\",',packages', 'pitted', 'plain' ,'thin' ,'ea','-inch' ,'inch' ,'cube', 'cubes','thinly','tiny','finely','[','ml', 'cup',\"cups\",'can','cans', \"liter\",\"-in\",\"liters\", 'g', 'oz', 'kg', 'cm','lb','-lb' ,'tbsp', 'kgs','tsp', 'l',\"ea\",\"ounces\",\"lbs\",\"peeled\",\"roasted\"]\n",
    "\n",
    "    for result in data['data']:\n",
    "        d= result[u'ingredients'][u'ungrouped'][u'list']\n",
    "        for a in d:\n",
    "            actual_unit = a['unit']\n",
    "\n",
    "            m= a['description']\n",
    "\n",
    "            m = re.sub(\"g\\.\",\"g\",m)\n",
    "            m = re.sub(\"\\. \",\" \",m)\n",
    "            word_tokens = word_tokenize(m) \n",
    "            m  = (\" \").join(word_tokens)\n",
    "       \n",
    "            split_string1 = m.split(',')\n",
    "\n",
    "            done = 0\n",
    "            if \",\" in m:\n",
    "                patterns1 = \"\"\"P: {<NN><,><NN>}\n",
    "                                {<VBD><,><VBD>}\n",
    "                                {<JJ><,><JJ>}    \n",
    "                                {<VBN><,><VBN>}\"\"\"  \n",
    "                PChunker1 = RegexpParser(patterns1)\n",
    "                output_pattern1 = PChunker1.parse(preprocess1(m))\n",
    "                for child in output_pattern1:\n",
    "                    if isinstance(child, Tree):              \n",
    "                        if child.label() == 'P':\n",
    "\n",
    "                            if (child[0][1] == \"VBD\") and len(split_string1)<3:\n",
    "                                done=1\n",
    "                                substring2 = split_string1[0] + \",\" +split_string1[1]\n",
    "                            elif child[0][1] == \"NN\" or child[0][1] == \"VBN\" or child[0][1] == \"JJ\":\n",
    "                                done=1\n",
    "                                substring2 = split_string1[0] + \",\" +split_string1[1]\n",
    "            if done == 0:\n",
    "                substring2 = split_string1[0]         \n",
    "            substring2 = re.sub(\"and/or\",\"or\",substring2)\n",
    "            substring2 = re.sub(\"or/and\",\"or\",substring2)\n",
    "            split_string = substring2.split(' or ')\n",
    "            substring1 = \"\"\n",
    "            \n",
    "            done = 0\n",
    "            patterns = \"\"\"P: {<JJ><CC><JJ>}\n",
    "                             {<VBD><CC><VB>}\n",
    "                             {<NN><CC><JJ>}\n",
    "                             {<VBD><CC><JJ>}\n",
    "                             {<CD><CC><CD>}\"\"\" \n",
    "            PChunker = RegexpParser(patterns)\n",
    "            if \" or \" in substring2:\n",
    "                found_pat = PChunker.parse(preprocess1(substring2))\n",
    "\n",
    "                for child in found_pat:\n",
    "                    if isinstance(child, Tree):               \n",
    "                        if child.label() == 'P':\n",
    "                            if child[1][0] == \"or\":\n",
    "                                done=1\n",
    "                                \n",
    "                                substring1 = split_string[1]\n",
    "\n",
    "            if done ==0:\n",
    "                substring1 = split_string[0]\n",
    "\n",
    "            substring1 = substring1.lower()\n",
    "            index = 0\n",
    "            u = \"x\"\n",
    "            for x in units:\n",
    "                finding = max(substring1.find(x),0)\n",
    "                if finding > index:\n",
    "                  index =finding\n",
    "                  u = x\n",
    "                  if actual_unit != None and u.strip() == actual_unit.strip():\n",
    "                      break\n",
    "                    \n",
    "            if u == \"x\" and a['unit'] != None:\n",
    "                u = a['unit']\n",
    "            \n",
    "\n",
    "            s = substring1\n",
    "            pattern1 = r\"(\\d+){}\".format(u)\n",
    "            pattern2 = r\"(\\d+/\\d+){}\".format(u)\n",
    "            pattern3 = r\"(\\d+.\\d+){}\".format(u)\n",
    "\n",
    "            if len(re.findall(pattern2, s))>0:\n",
    "                quantity_product = re.findall(pattern2, s)[0]\n",
    "\n",
    "            elif len(re.findall(pattern1, s))>0:\n",
    "                if len(re.findall(pattern3, s))>0:\n",
    "                    quantity_product = re.findall(pattern3, s)[0]\n",
    "\n",
    "                else:\n",
    "                    quantity_product = re.findall(pattern1, s)[0]\n",
    "            else:\n",
    "                quantity_product = a['quantity']\n",
    "                \n",
    "            if index !=0:\n",
    "                index = index + len(u.strip())+1\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            substring3 = substring1\n",
    "            substring3 = re.sub(\"\\(.*?\\)\",\"\",substring3)\n",
    "            \n",
    "            \n",
    "            index = [i for i in range(len(substring3)) if substring3.startswith(\"(\", i)]\n",
    "\n",
    "            if len(index) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                index = index[0]\n",
    "                substring3 = substring3[:index]  \n",
    "\n",
    "\n",
    "            index = [i for i in range(len(substring3)) if substring3.startswith(\")\", i)]\n",
    "\n",
    "            if len(index) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                index = index[-1]\n",
    "                substring3 = substring3[index+1:]      \n",
    "            x = re.findall(\"\\d\", substring3)\n",
    "\n",
    "            for aaa in set(x):\n",
    "                substring3 = re.sub(aaa,\"\",substring3)\n",
    "            substring4 = substring3\n",
    "            word_tokens = word_tokenize(substring4) \n",
    "            filtered_sentence = [wnl.lemmatize(w) for w in word_tokens if not w in unknow_words+units_remove] \n",
    "            substring4  = (\" \").join(filtered_sentence)\n",
    "\n",
    "\n",
    "            substring4 = substring4.strip(\",\")\n",
    "            substring4 = substring4.strip()\n",
    "             \n",
    "            u = u.strip()\n",
    "            \n",
    "\n",
    "            try:\n",
    "                quantity_product =float(quantity_product)\n",
    "                if u == 'litres' or u == 'litre' or u == \"liter\" or u == \"liters\" or u == \"ml\" or u == \"l\":\n",
    "                    if u == \"ml\":\n",
    "                        quantity_product = quantity_product/1000\n",
    "                    u=\"l\"\n",
    "                elif u == \"kgs\" or u == \"kg\" or u == \"g\":\n",
    "                    if u == \"g\":\n",
    "                        quantity_product = quantity_product/1000\n",
    "                    u=\"kg\"\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "\n",
    "            for bi in bigram:\n",
    "                if bi in substring4:\n",
    "                    substring4 = re.sub(bi,\"\",substring4)\n",
    "            \n",
    "            output_converter = convert_unit(substring4,u,quantity_product,ml,gram)\n",
    "\n",
    "            quantity_product,u = output_converter[0],output_converter[1]\n",
    "\n",
    "            des.append(substring4)\n",
    "            quantity.append(quantity_product)\n",
    "            unit.append(u)\n",
    "            df =pd.DataFrame(zip(des,quantity,unit),columns=[\"food\",\"quantity\",\"unit\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spaces(text):\n",
    "    return \" \"+text+\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "k4pUZWr4LcnT"
   },
   "outputs": [],
   "source": [
    "def create_category_list():\n",
    "  bakery = []\n",
    "  with open(\"categories_data/Bakery.txt\") as f:\n",
    "    bakery = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  chilled = []\n",
    "  with open(\"categories_data/Chilled.txt\") as f:\n",
    "    chilled = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  beverages = []\n",
    "  with open(\"categories_data/Beverages.txt\") as f:\n",
    "    beverages = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  dairy = []\n",
    "  with open(\"categories_data/Dairy_Eggs.txt\") as f:\n",
    "    dairy = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  fruit = []\n",
    "  with open(\"categories_data/Fruit_Vegetables.txt\") as f:\n",
    "    fruit = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  grains = []\n",
    "  with open(\"categories_data/Grains_Beans.txt\") as f:\n",
    "    grains = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  herbs = []\n",
    "  with open(\"categories_data/Herbs_Spices.txt\") as f:\n",
    "    herbs = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  meat = []\n",
    "  with open(\"categories_data/Meat_Fish _Alternatives.txt\") as f:\n",
    "    meat = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "    \n",
    "  nuts = []\n",
    "  with open(\"categories_data/Nuts_Seeds.txt\") as f:\n",
    "    nuts =[add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "    \n",
    "  pantry = []\n",
    "  with open(\"categories_data/Pantry.txt\") as f:\n",
    "    pantry = [add_spaces(wnl.lemmatize(re.sub(\"\\n\",\"\",a).strip().lower())) for a in f.readlines()]\n",
    "\n",
    "  return bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g8pm-4xALcnU"
   },
   "outputs": [],
   "source": [
    "def name_cat(name,bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry):\n",
    "  for a in bakery:\n",
    "    if a in name and len(a)>0:\n",
    "      return 0\n",
    "\n",
    "  for a in chilled:\n",
    "    if a in name and len(a)>0:\n",
    "      return 1\n",
    "\n",
    "  for a in beverages:\n",
    "    if a in name and len(a)>0:\n",
    "      return 2\n",
    "\n",
    "  for a in dairy:\n",
    "    if a in name and len(a)>0:\n",
    "      return 3\n",
    "\n",
    "  for a in fruit:\n",
    "    if a in name and len(a)>0:\n",
    "      return 4\n",
    "\n",
    "  for a in grains:\n",
    "    if a in name and len(a)>0:\n",
    "      return 5\n",
    "\n",
    "  for a in herbs:\n",
    "    if a in name and len(a)>0:\n",
    "      return 6\n",
    "\n",
    "  for a in meat:\n",
    "    if a in name and len(a)>0:\n",
    "      return 7\n",
    "\n",
    "  for a in nuts:\n",
    "    if a in name and len(a)>0:\n",
    "      return 8\n",
    "\n",
    "  for a in pantry:\n",
    "    if a in name and len(a)>0:\n",
    "      return 9\n",
    "\n",
    "  return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TS9wwV9bN9Dy"
   },
   "outputs": [],
   "source": [
    "def main_function(input_json):\n",
    "    \n",
    "    \n",
    "    ml,gram = read_units()\n",
    "    df = process(input_json,ml,gram)\n",
    "    df1 = df.groupby([\"food\",\"unit\"])\n",
    "    bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry = create_category_list()\n",
    "    json_bakery = []\n",
    "    json_chilled = []\n",
    "    json_beverages=[] \n",
    "    json_dairy =[] \n",
    "    json_fruit=[]\n",
    "    json_grains =[] \n",
    "    json_herbs = []\n",
    "    json_meat =[]\n",
    "    json_nuts =[]\n",
    "    json_pantry =[]\n",
    "    json_others = []\n",
    "    for name,group in df1:\n",
    "        new = {}\n",
    "        new[\"ingredient\"]=name[0]\n",
    "        try:\n",
    "            if name[1] == \"l\" and group[\"quantity\"].sum()<1:\n",
    "                new[\"unit\"]=\"ml\"\n",
    "                new[\"quantity\"]=float(group[\"quantity\"].sum()*1000)\n",
    "            elif name[1] ==\"kg\" and group[\"quantity\"].sum()<1:\n",
    "                new[\"unit\"]=\"g\"\n",
    "                new[\"quantity\"]=float(group[\"quantity\"].sum()*1000)\n",
    "            else:\n",
    "                new[\"unit\"]=name[1]\n",
    "                if round(group[\"quantity\"].sum(),2) == int(group[\"quantity\"].sum())+0.99:\n",
    "                    new[\"quantity\"] = round(group[\"quantity\"].sum(),0)\n",
    "                else:\n",
    "                    new[\"quantity\"]=round(group[\"quantity\"].sum(),2)\n",
    "        except:\n",
    "            \n",
    "            new[\"unit\"]=name[1]\n",
    "            total = 0\n",
    "            \n",
    "            for qw in group[\"quantity\"]:\n",
    "                a = qw.split(\"/\")\n",
    "                \n",
    "                a1 = int(a[0])\n",
    "                a2 = int(a[1])\n",
    "                total = total + a1/a2\n",
    "                \n",
    "            if round(total,2) == 0.33:\n",
    "                quantity = \"1/3\"\n",
    "            else:\n",
    "                out = (total).as_integer_ratio()\n",
    "                quantity = str(out[0])+\"/\"+str(out[1])\n",
    "                if out[0] == out[1]:\n",
    "                    quantity = out[0]\n",
    "            \n",
    "            new[\"quantity\"] = quantity\n",
    "        cat = name_cat(add_spaces(name[0]),bakery,chilled,beverages, dairy, fruit,grains,herbs,meat,nuts,pantry) \n",
    "        if cat == 0:\n",
    "            json_bakery.append(new)\n",
    "        elif cat == 1:\n",
    "            json_chilled.append(new)\n",
    "        elif cat == 2:\n",
    "            json_beverages.append(new)\n",
    "        elif cat == 3:\n",
    "            json_dairy.append(new)\n",
    "        elif cat == 4:\n",
    "            json_fruit.append(new)\n",
    "        elif cat == 5:\n",
    "            json_grains.append(new)\n",
    "        elif cat == 6:\n",
    "            json_herbs.append(new)\n",
    "        elif cat == 7:\n",
    "            json_meat.append(new)\n",
    "        elif cat == 8:\n",
    "            json_nuts.append(new)\n",
    "        elif cat == 9:\n",
    "            json_pantry.append(new)\n",
    "        elif cat == 10:\n",
    "            json_others.append(new)\n",
    "\n",
    "\n",
    "\n",
    "    final = {\"Pantry\":json_pantry,\"Beverages\":json_beverages,\"Fruits and Vegetables\":json_fruit,\n",
    "             \"Meat,Fish and Alternatives\":json_meat,\"Dairy and Eggs\":json_dairy,\n",
    "             \"Chilled\":json_chilled,\"Grains and Beans\":json_grains,\"Herbs and Spices\":json_herbs,\n",
    "             \"Nuts and Seeds\":json_nuts,\"Bakery\":json_bakery,\"You may also need\":json_others}\n",
    "    return final\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "f = open('total.json')\n",
    "data = json.load(f)\n",
    "aa = main_function(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.json\", \"w\",encoding=\"utf-8\") as outfile: \n",
    "    json.dump(aa, outfile,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "food_extraction_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
